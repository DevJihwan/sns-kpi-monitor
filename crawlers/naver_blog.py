import os
import requests
from datetime import datetime
from typing import List, Dict
import time
import re

class NaverBlogCrawler:
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ URL ìˆ˜ì§‘"""
    
    def __init__(self):
        self.client_id = os.getenv('NAVER_CLIENT_ID')
        self.client_secret = os.getenv('NAVER_CLIENT_SECRET')
        self.base_url = "https://openapi.naver.com/v1/search/blog.json"
        
        if not self.client_id or not self.client_secret:
            raise ValueError("NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETì„ .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
    def search(self, keyword: str, display: int = 100, start: int = 1) -> Dict:
        """
        ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            display: í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê²°ê³¼ ìˆ˜ (ìµœëŒ€ 100)
            start: ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (1~1000)
        
        Returns:
            API ì‘ë‹µ ê²°ê³¼
        """
        headers = {
            'X-Naver-Client-Id': self.client_id,
            'X-Naver-Client-Secret': self.client_secret
        }
        
        params = {
            'query': keyword,
            'display': display,
            'start': start,
            'sort': 'date'  # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        }
        
        try:
            response = requests.get(self.base_url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ìš”ì²­ ì—ëŸ¬: {e}")
            return None
    
    def collect_by_keyword(self, keyword: str, max_results: int = 1000) -> List[Dict]:
        """
        í‚¤ì›Œë“œë¡œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ URL ìˆ˜ì§‘
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_results: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ (API ì œí•œ: ìµœëŒ€ 1000)
        
        Returns:
            ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        all_posts = []
        display = 100  # í•œ ë²ˆì— 100ê°œì”©
        max_results = min(max_results, 1000)  # API ì œí•œ
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ API ìˆ˜ì§‘ ì‹œì‘: '{keyword}'")
        print(f"{'='*60}")
        
        for start in range(1, max_results + 1, display):
            current_display = min(display, max_results - start + 1)
            print(f"ğŸ“¥ ìˆ˜ì§‘ ì¤‘: {start}~{start + current_display - 1}ë²ˆì§¸...")
            
            result = self.search(keyword, current_display, start)
            if not result or 'items' not in result:
                print("âš ï¸ ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            items = result['items']
            if not items:
                print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            for item in items:
                post_data = {
                    'platform': 'ë„¤ì´ë²„ ë¸”ë¡œê·¸',
                    'region': 'êµ­ë‚´',
                    'keyword': keyword,
                    'title': self._clean_html(item['title']),
                    'description': self._clean_html(item['description']),
                    'blogger_name': item['bloggername'],
                    'blogger_id': item['bloggerlink'].split('/')[-1] if item['bloggerlink'] else '',
                    'post_url': item['link'],
                    'post_date': self._parse_date(item['postdate']),
                    'collected_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    # ìƒì„¸ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ì¶”ê°€ë  ì˜ˆì •
                    'views': None,
                    'comments': None,
                    'likes': None
                }
                all_posts.append(post_data)
            
            # API í˜¸ì¶œ ì œí•œ ëŒ€ì‘ (ì´ˆë‹¹ 10íšŒ ì œí•œ)
            time.sleep(0.15)
            
            # ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if len(items) < current_display:
                break
        
        print(f"âœ… ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_posts)}ê°œ")
        return all_posts
    
    def _clean_html(self, text: str) -> str:
        """HTML íƒœê·¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
        if not text:
            return ""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub('<[^<]+?>', '', text)
        # HTML ì—”í‹°í‹° ë³€í™˜
        text = text.replace('&nbsp;', ' ')
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        text = text.replace('&amp;', '&')
        text = text.replace('&quot;', '"')
        text = text.replace('&#39;', "'")
        return text.strip()
    
    def _parse_date(self, date_str: str) -> str:
        """ë‚ ì§œ í¬ë§· ë³€í™˜ (YYYYMMDD -> YYYY-MM-DD)"""
        try:
            if len(date_str) == 8:
                return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
            return date_str
        except:
            return date_str
